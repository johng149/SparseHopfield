{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "exlq46O9zfGw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import einops\n",
        "from torch.nn import Module, Parameter, ParameterList\n",
        "from torch import Tensor\n",
        "from collections import namedtuple\n",
        "from typing import List\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsEMqglEiKCR",
        "outputId": "4dff0b30-5285-43db-e017-da79ca15d9de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c6c7ffd3c10>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uuv7HyJC1oKo"
      },
      "outputs": [],
      "source": [
        "LayerInfo = namedtuple(\"LayerInfo\", [\"nodes\", \"memories\"]) # num nodes, num mems per node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EQNAHQdQzqay"
      },
      "outputs": [],
      "source": [
        "class SparseHopfield(Module):\n",
        "  def __init__(self, receptive_fields, field_dim, layers: List[LayerInfo], t: int = 0, alpha: float=1.0, rho=1e-8):\n",
        "    super().__init__()\n",
        "    self.fields = receptive_fields\n",
        "    self.field_dim = field_dim\n",
        "    self.layers_info = layers\n",
        "    self.t = t\n",
        "    self.a = alpha\n",
        "    self.rho = rho # used to prevent division by zero\n",
        "    self.kwargs = {\n",
        "        \"receptive_fields\": self.fields,\n",
        "        \"field_dim\": self.field_dim,\n",
        "        \"layers\": self.layers_info,\n",
        "        \"t\": self.t,\n",
        "        \"alpha\": self.a,\n",
        "        \"rho\": self.rho\n",
        "    }\n",
        "\n",
        "    self.growth_threshold = self.a / (self.t + self.a)\n",
        "    self.layers = []\n",
        "    self.layer_counts = []\n",
        "\n",
        "    self.create_layers()\n",
        "\n",
        "  def reset_iteration(self, t: int = 0):\n",
        "    self.t = t\n",
        "    self.growth_threshold = self.a / (self.t + self.a)\n",
        "\n",
        "  def update_iteration(self):\n",
        "    self.t += 1\n",
        "    self.growth_threshold = self.a / (self.t + self.a)\n",
        "\n",
        "  def create_layers(self):\n",
        "    for i in range(len(self.layers_info)):\n",
        "      if i == 0: # assume we are in outer layer\n",
        "        nodes, mems = self.layers_info[i]\n",
        "        nodes = self.fields # we ignore what layers info says, we need to match the fields here\n",
        "        self.layers_info[i] = LayerInfo(nodes=nodes, memories=mems)\n",
        "        dim = self.field_dim\n",
        "        counts = torch.ones(nodes, mems)\n",
        "        mem_matrix = Parameter(torch.zeros((nodes, mems, dim)) + 0.5, requires_grad=False)\n",
        "        self.layers.append(mem_matrix)\n",
        "        self.layer_counts.append(counts)\n",
        "      else:\n",
        "        nodes, mems = self.layers_info[i]\n",
        "        prev_nodes, prev_mems = self.layers_info[i - 1]\n",
        "        assert prev_nodes % nodes == 0, f\"At layer {i}, prev is {prev_nodes} but nodes is {nodes}\"\n",
        "        children_per_node = prev_nodes // nodes\n",
        "        counts = torch.ones(nodes, mems)\n",
        "        mem_matrix = Parameter(torch.zeros((nodes, children_per_node, mems, prev_mems)), requires_grad=False)\n",
        "        self.layers.append(mem_matrix)\n",
        "        self.layer_counts.append(counts)\n",
        "      self.layers = ParameterList(self.layers)\n",
        "\n",
        "  @staticmethod\n",
        "  def maxi(x):\n",
        "    max_indices = torch.argmax(x, dim=-1, keepdim=True)\n",
        "    blank = torch.zeros_like(x)\n",
        "    return torch.scatter(blank, -1, max_indices, torch.gather(x, -1, max_indices))\n",
        "\n",
        "  @staticmethod\n",
        "  def argmaxi(x, eps=1e-8):\n",
        "    maxied = torch.abs(SparseHopfield.maxi(x))\n",
        "    factors, indices = torch.max(maxied, dim=-1)\n",
        "    factors = factors - eps\n",
        "    return maxied / factors.unsqueeze(-1)\n",
        "\n",
        "  @staticmethod\n",
        "  def mark_reserved_indices(acts, usages, trigger_growth, mark=-2):\n",
        "    used_values, used_indices = torch.sort(acts, dim=-1)\n",
        "    used_values, used_indices\n",
        "    reservations = used_indices[:,:,-1:]\n",
        "    reservations[trigger_growth] = -1\n",
        "    reservations = einops.rearrange(reservations, 'batch mems flag -> mems (batch flag)')\n",
        "    sorts, sort_indices = torch.sort(usages, dim=-1)\n",
        "    sorts, sort_indices, reservations\n",
        "    reservation_mask = reservations != -1\n",
        "    expanded_usages = sort_indices.unsqueeze(1).expand(-1, reservations.size(1), -1)\n",
        "    expanded_res = reservations.unsqueeze(-1).expand(-1, -1, usages.size(1))\n",
        "    matches = (expanded_res == expanded_usages) & reservation_mask.unsqueeze(-1)\n",
        "    matches = matches.any(dim=1)\n",
        "    return torch.where(matches, -2, sort_indices), sort_indices\n",
        "\n",
        "  @staticmethod\n",
        "  def move_value_to_back(x, value=-2):\n",
        "    # moves all instances of `value` in `x` to the right most along the last dim\n",
        "    # for example, if x is\n",
        "    # [ [-2, 1, 2, 2, 3], [0, -2, 1, -2, 3]]\n",
        "    # and value is -2, the result is\n",
        "    # [ [1, 2, 2, 3, -2], [0, 1, 3, -2, -2]]\n",
        "    # intended to be used with 2d tensors\n",
        "    indices = (x == value).argsort(dim=-1, stable=True)\n",
        "    return torch.gather(x, -1, indices)\n",
        "\n",
        "  @staticmethod\n",
        "  def expand_for_batches(x, batch_size):\n",
        "    nodes, mems = x.shape\n",
        "    full_expands = (batch_size // mems) + 1\n",
        "    residual = batch_size % mems\n",
        "    return x.unsqueeze(0).expand(full_expands, -1, -1).transpose(0, 1).reshape(nodes, -1)[:, :batch_size]\n",
        "\n",
        "  @staticmethod\n",
        "  def growth_argmaxi(x, counts, eps=1e-8, threshold=0.9):\n",
        "    # for now we assume batch_size is 1\n",
        "    batch_size, nodes, mems = x.shape\n",
        "    normal_path = SparseHopfield.argmaxi(x, eps)\n",
        "    trigger_growth = torch.sum(x > threshold, dim=-1, keepdim=True) <= 0\n",
        "    mark = -2\n",
        "    avail, all = SparseHopfield.mark_reserved_indices(normal_path, counts, trigger_growth, mark)\n",
        "    avail = SparseHopfield.move_value_to_back(avail, mark)\n",
        "    avail = SparseHopfield.expand_for_batches(avail, batch_size)\n",
        "    all = SparseHopfield.expand_for_batches(all, batch_size)\n",
        "    final = torch.where(avail == mark, all, avail)\n",
        "    indices_sg = final.transpose(-1, -2).reshape(batch_size, -1, 1)\n",
        "    growth_path = torch.zeros_like(normal_path)\n",
        "    values_of_interest = torch.gather(x, -1, indices_sg)\n",
        "    values_of_interest[values_of_interest == 0] = 1\n",
        "    # taking a closer look, it doesn't seem like the exact values from\n",
        "    # the original should matter, we were just using it to divide\n",
        "    # by itself (minus an eps) in the argmaxi to turn them into 1s,\n",
        "    # to just setting it to 1 should be fine?\n",
        "    # follow up: No, need the exact values from original. If we don't we\n",
        "    # won't break the network, but we will break the gradient flows\n",
        "    # and although this network doesn't use backprop, the layers that\n",
        "    # occur earlier might want those gradients\n",
        "    growth_path = torch.scatter(growth_path, -1, indices_sg, values_of_interest)\n",
        "    growth_path = SparseHopfield.argmaxi(torch.abs(growth_path), eps)\n",
        "    grown = torch.where(trigger_growth, growth_path, normal_path)\n",
        "\n",
        "    updated_counts = einops.reduce(grown, 'batch nodes mems -> nodes mems', 'sum')\n",
        "    updated_counts = torch.where(updated_counts <= 0, counts, updated_counts)\n",
        "\n",
        "    return grown, updated_counts.detach()\n",
        "\n",
        "  @staticmethod\n",
        "  def outer_forward_parallel(mems, xs, rho=1e-8):\n",
        "    batch_size, fields, dim = xs.shape\n",
        "\n",
        "    # if mems only has 3 dimensions, then we know it is missing the batch dim,\n",
        "    # this is because the shape of mems should be\n",
        "    # batch_size x fields x memories x dim\n",
        "    m = mems - 0.5 if mems.dim() == 4 else (mems - 0.5).expand(batch_size, -1, -1, -1)\n",
        "    x = xs - 0.5\n",
        "    numerator = einops.einsum(m,x, 'batch fields memories dim, batch fields dim -> batch fields memories') * 0.5\n",
        "    m_norm = torch.sqrt(einops.reduce(m ** 2, 'batch fields memories dim -> batch fields memories', 'sum'))\n",
        "    x_norm = torch.sqrt(einops.reduce(x ** 2, 'batch field dim -> batch field', 'sum')).unsqueeze(-1)\n",
        "    denom = m_norm * x_norm + rho\n",
        "    return (numerator / denom) + 0.5\n",
        "\n",
        "  @staticmethod\n",
        "  def hidden_forward_parallel(hidden_mm, children_x, rho=1e-8):\n",
        "    batch_size, total_children, children_mem_cols = children_x.shape\n",
        "    if hidden_mm.dim() == 4:\n",
        "      num_hidden_nodes, children_per_hidden, hidden_mems, children_mem_cols = hidden_mm.shape\n",
        "      mm = hidden_mm.expand(batch_size, -1, -1, -1, -1)\n",
        "    else:\n",
        "      batch_size, num_hidden_nodes, children_per_hidden, hidden_mems, children_mem_cols = hidden_mm.shape\n",
        "      mm = hidden_mm\n",
        "    x = SparseHopfield.maxi(children_x).reshape(batch_size, num_hidden_nodes, children_per_hidden, children_mem_cols)\n",
        "    propagation = einops.einsum(mm, x, 'batch hidden children h_mems c_mems, batch hidden children c_mems -> batch hidden h_mems')\n",
        "    x_norm = torch.sqrt(einops.reduce(x**2,'batch hidden children c_mems -> batch hidden', 'sum')).unsqueeze(-1)\n",
        "    norm_coeff = 1 / ((children_per_hidden * x_norm) + rho)\n",
        "    return propagation * norm_coeff\n",
        "\n",
        "  @staticmethod\n",
        "  def down_prop_parallel(parent_h, parent_mm, child_h, coeff=0.5):\n",
        "    # we assume `parent_h` has already been passed through argmaxi\n",
        "    # in other words down_prop_parallel(argmaxi(parent_h), ...)\n",
        "    batch_size, children, children_dim = child_h.shape\n",
        "    if parent_mm.dim() == 4:\n",
        "      mm = parent_mm.expand(batch_size, -1, -1, -1, -1)\n",
        "    else:\n",
        "      mm = parent_mm\n",
        "    batch_size, parent_nodes, children_per_parent, parent_dim, child_dim = mm.shape\n",
        "    argmaxi_parent_h = parent_h.unsqueeze(-2).expand(-1,-1, children_per_parent, -1)\n",
        "    orig = child_h * coeff\n",
        "    new = (1 - coeff) * einops.einsum(argmaxi_parent_h, mm, 'batch parents children pdim, batch parents children pdim cdim -> batch parents children cdim')\n",
        "    new = new.reshape(batch_size, children, -1)\n",
        "    return orig + new\n",
        "\n",
        "  @staticmethod\n",
        "  def pred(parent_down_prop, parent_mem_matrix):\n",
        "    mm = parent_mem_matrix if parent_mem_matrix.dim() != 3 else parent_mem_matrix.unsqueeze(-3)\n",
        "    nodes, children_per_node, memories, dim = mm.shape\n",
        "    batch_size, nodes, memories = parent_down_prop.shape\n",
        "    prediction = einops.einsum(mm, parent_down_prop, 'nodes children_per_node memories dim, batch nodes memories -> batch nodes children_per_node dim')\n",
        "    prediction = prediction.reshape(batch_size, nodes * children_per_node, dim)\n",
        "    return prediction\n",
        "\n",
        "  @staticmethod\n",
        "  def mem_delta(parent_down_prop, parent_mem_matrix, child_down_prop):\n",
        "    \"\"\"\n",
        "    Calculates the delta that should be added to the given `parent_mem_matrix`\n",
        "    to optimize the model. For example, to optimize the given matrix, use\n",
        "    `new_mm = old_mm + lr * mem_delta(p_prop, old_mm, c_prop)`\n",
        "    Note that the `lr` scaling should be done outside of this function\n",
        "\n",
        "    Note also that, according to the paper / reference implementation, when\n",
        "    calculating the matrix update for the outer layer, the child down prop is\n",
        "    just the raw inputs, not one that is one-hot encoded\n",
        "    \"\"\"\n",
        "    # shape is nodes memories dim, but we want\n",
        "    # nodes children_per_node memories dim\n",
        "    # in this case, we'll assume that children_per_node is 1\n",
        "    mm = parent_mem_matrix if parent_mem_matrix.dim() != 3 else parent_mem_matrix.unsqueeze(-3)\n",
        "    nodes, children_per_node, memories, dim = mm.shape\n",
        "    batch_size, nodes, memories = parent_down_prop.shape\n",
        "\n",
        "    prediction = SparseHopfield.pred(parent_down_prop, mm)\n",
        "    error = child_down_prop - prediction\n",
        "    error = error.reshape(batch_size, nodes, children_per_node, dim)\n",
        "    delta = einops.einsum(error, parent_down_prop, 'batch nodes children_per_node dim, batch nodes memories -> nodes children_per_node memories dim')\n",
        "    return delta.reshape(parent_mem_matrix.shape)\n",
        "\n",
        "  def outer_up(self, sensor_input):\n",
        "    outer_mm = self.layers[0]\n",
        "    h_sub_l = SparseHopfield.outer_forward_parallel(outer_mm, sensor_input, self.rho)\n",
        "    return h_sub_l\n",
        "\n",
        "  def up(self, sensor_input):\n",
        "    upwards = [self.outer_up(sensor_input)]\n",
        "    for i in range(1, len(self.layers)):\n",
        "      mm = self.layers[i]\n",
        "      h_sub_l = SparseHopfield.hidden_forward_parallel(mm, upwards[i-1], self.rho)\n",
        "      upwards.append(h_sub_l)\n",
        "    return upwards\n",
        "\n",
        "  def root_down(self, upwards, eps=1e-6):\n",
        "    root_h_sub_l = upwards[-1]\n",
        "    root_counts = self.layer_counts[-1]\n",
        "    root_h_sub_l_star, root_counts = SparseHopfield.growth_argmaxi(root_h_sub_l, root_counts, eps, self.growth_threshold)\n",
        "    self.layer_counts[-1] = root_counts\n",
        "    return root_h_sub_l_star\n",
        "\n",
        "  def down(self, upwards, eps=1e-6, coeff=0.5):\n",
        "    downwards = [self.root_down(upwards, eps)]\n",
        "    for i in range(len(upwards)-2, -1, -1):\n",
        "      h_sub_l = upwards[i]\n",
        "      counts = self.layer_counts[i]\n",
        "      downed = SparseHopfield.down_prop_parallel(downwards[-1],self.layers[i+1],h_sub_l,coeff)\n",
        "      h_sub_l_star, counts = SparseHopfield.growth_argmaxi(downed, counts, eps, self.growth_threshold)\n",
        "      self.layer_counts[i] = counts\n",
        "      downwards.append(h_sub_l_star)\n",
        "    return downwards\n",
        "\n",
        "  def pred_root_down(self, upwards, eps=1e-6):\n",
        "    root_h_sub_l = upwards[-1]\n",
        "    root_counts = self.layer_counts[-1]\n",
        "    root_h_sub_l_star = SparseHopfield.argmaxi(root_h_sub_l, eps)\n",
        "    return root_h_sub_l_star\n",
        "\n",
        "  def pred_down(self, upwards, eps=1e-6, coeff=0.5):\n",
        "    downwards = [self.pred_root_down(upwards, eps)]\n",
        "    for i in range(len(upwards)-2, -1, -1):\n",
        "      h_sub_l = upwards[i]\n",
        "      counts = self.layer_counts[i]\n",
        "      downed = SparseHopfield.down_prop_parallel(downwards[-1],self.layers[i+1],h_sub_l,coeff)\n",
        "      h_sub_l_star = SparseHopfield.argmaxi(downed, eps)\n",
        "      downwards.append(h_sub_l_star)\n",
        "    return downwards\n",
        "\n",
        "  def delta_outer(self, downwards, sensory_input):\n",
        "    outer_mm = self.layers[0]\n",
        "    outer_h_sub_l_star = downwards[-1]\n",
        "    outer_delta = SparseHopfield.mem_delta(outer_h_sub_l_star, outer_mm, sensory_input)\n",
        "    return outer_delta\n",
        "\n",
        "  def delta(self, downwards, sensory_input):\n",
        "    deltas = [self.delta_outer(downwards, sensory_input)]\n",
        "    for i in range(1, len(downwards)):\n",
        "      child_h_sub_l_star = downwards[len(downwards) - i]\n",
        "      h_sub_l_star = downwards[len(downwards) - i - 1]\n",
        "      mm = self.layers[i]\n",
        "      delta = SparseHopfield.mem_delta(h_sub_l_star, mm, child_h_sub_l_star)\n",
        "      deltas.append(delta)\n",
        "    return deltas\n",
        "\n",
        "  def optim_outer(self, deltas):\n",
        "    outer_delta = deltas[0]\n",
        "    outer_mm = self.layers[0]\n",
        "    outer_counts = self.layer_counts[0]\n",
        "    delta = outer_delta / (outer_counts).unsqueeze(-1)\n",
        "    self.layers[0] = outer_mm + delta\n",
        "\n",
        "  def optim(self, deltas):\n",
        "    self.optim_outer(deltas)\n",
        "    for i in range(1, len(deltas)):\n",
        "      delta = deltas[i]\n",
        "      mm = self.layers[i]\n",
        "      count = self.layer_counts[i]\n",
        "      delta = delta / (count).unsqueeze(-1).unsqueeze(-3)\n",
        "      self.layers[i] = mm + delta\n",
        "    self.update_iteration()\n",
        "\n",
        "  def optimize(self, sensory_input, eps=1e-6, coeff=0.5):\n",
        "    upwards = self.up(sensory_input)\n",
        "    downwards = self.down(upwards, eps, coeff)\n",
        "    deltas = self.delta(downwards, sensory_input)\n",
        "    self.optim(deltas)\n",
        "\n",
        "  def predict(self, sensory_input, eps=1e-6, coeff=0.5):\n",
        "    with torch.no_grad():\n",
        "      upwards = self.up(sensory_input)\n",
        "      downwards = self.pred_down(upwards, eps, coeff)\n",
        "      prediction = SparseHopfield.pred(downwards[-1],self.layers[0])\n",
        "      return prediction\n",
        "\n",
        "  def prediction_error(self, sensory_input, eps=1e-6, coeff=0.5):\n",
        "    with torch.no_grad():\n",
        "      pred = self.predict(sensory_input, eps, coeff)\n",
        "      return torch.mean(torch.square(pred - sensory_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VyztP0gibIB1"
      },
      "outputs": [],
      "source": [
        "def losses(net, batch):\n",
        "  batch_size, fields, dim = batch.shape\n",
        "  total = 0\n",
        "  losses = []\n",
        "  for i in range(batch_size):\n",
        "    err = net.prediction_error(batch[i].unsqueeze(0))\n",
        "    total += err\n",
        "    losses.append(err)\n",
        "  total = total / batch_size\n",
        "  return total, losses\n",
        "\n",
        "def train(net, batch):\n",
        "  batch_size, fields, dim = batch.shape\n",
        "  for i in range(batch_size):\n",
        "    net.optimize(batch[i].unsqueeze(0))\n",
        "\n",
        "def train_batched(net, batch):\n",
        "  net.optimize(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Lp9Se0aP9gy9"
      },
      "outputs": [],
      "source": [
        "layers: List[LayerInfo] = [\n",
        "    LayerInfo(nodes=-1, memories=16),\n",
        "    LayerInfo(nodes=3, memories=16),\n",
        "    LayerInfo(nodes=1, memories=16)\n",
        "]\n",
        "receptive_fields = 3\n",
        "field_dim = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CPqSlqm69kaT"
      },
      "outputs": [],
      "source": [
        "net = SparseHopfield(receptive_fields=receptive_fields,field_dim=field_dim,layers=layers, alpha=100.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x7HuJ9xRU9Mn"
      },
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zzfV-UkxcZcI"
      },
      "outputs": [],
      "source": [
        "sensory_input = torch.randn(batch_size, receptive_fields, field_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QGm29zJbjAR",
        "outputId": "f85e9390-40c2-45ce-d26c-658cb1c09c27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1.2579),\n",
              " [tensor(1.4728),\n",
              "  tensor(1.3954),\n",
              "  tensor(0.6899),\n",
              "  tensor(1.0774),\n",
              "  tensor(1.2106),\n",
              "  tensor(1.7881),\n",
              "  tensor(1.1134),\n",
              "  tensor(1.3157)])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5CBlpz6EbmtE"
      },
      "outputs": [],
      "source": [
        "#train(net, sensory_input)\n",
        "train_batched(net, sensory_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtHOc357botJ",
        "outputId": "100605d3-1612-407a-c8c0-15fb004d4ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(4.8052e-12),\n",
              " [tensor(6.1988e-12),\n",
              "  tensor(4.9543e-12),\n",
              "  tensor(3.8494e-12),\n",
              "  tensor(4.5183e-12),\n",
              "  tensor(3.4559e-12),\n",
              "  tensor(4.9506e-12),\n",
              "  tensor(5.5733e-12),\n",
              "  tensor(4.9412e-12)])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gEr143bVkvub"
      },
      "outputs": [],
      "source": [
        "sensory_input_2 = torch.randn(batch_size, receptive_fields, field_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1.4067),\n",
              " [tensor(1.2404),\n",
              "  tensor(1.0824),\n",
              "  tensor(1.0607),\n",
              "  tensor(2.5665),\n",
              "  tensor(1.1240),\n",
              "  tensor(1.1473),\n",
              "  tensor(0.8762),\n",
              "  tensor(2.1557)])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_batched(net, sensory_input_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(4.6949e-12),\n",
              " [tensor(3.6796e-12),\n",
              "  tensor(4.6915e-12),\n",
              "  tensor(3.6933e-12),\n",
              "  tensor(5.5895e-12),\n",
              "  tensor(5.3081e-12),\n",
              "  tensor(5.0567e-12),\n",
              "  tensor(3.5383e-12),\n",
              "  tensor(6.0024e-12)])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(4.8052e-12),\n",
              " [tensor(6.1988e-12),\n",
              "  tensor(4.9543e-12),\n",
              "  tensor(3.8494e-12),\n",
              "  tensor(4.5183e-12),\n",
              "  tensor(3.4559e-12),\n",
              "  tensor(4.9506e-12),\n",
              "  tensor(5.5733e-12),\n",
              "  tensor(4.9412e-12)])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1.5941),\n",
              " [tensor(1.1838),\n",
              "  tensor(1.2113),\n",
              "  tensor(2.1562),\n",
              "  tensor(2.1673),\n",
              "  tensor(2.9801),\n",
              "  tensor(1.1198),\n",
              "  tensor(1.0297),\n",
              "  tensor(0.9043)])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sensory_input_3 = torch.randn(batch_size, receptive_fields, field_dim)\n",
        "losses(net, sensory_input_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_batched(net, sensory_input_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(4.4759e-12),\n",
              " [tensor(2.5152e-12),\n",
              "  tensor(2.0300e-12),\n",
              "  tensor(1.6342e-12),\n",
              "  tensor(4.7505e-12),\n",
              "  tensor(1.2338e-11),\n",
              "  tensor(1.2813e-12),\n",
              "  tensor(2.5480e-12),\n",
              "  tensor(8.7101e-12)])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.0792),\n",
              " [tensor(0.6334),\n",
              "  tensor(4.6915e-12),\n",
              "  tensor(3.6933e-12),\n",
              "  tensor(5.5895e-12),\n",
              "  tensor(5.3081e-12),\n",
              "  tensor(5.0567e-12),\n",
              "  tensor(3.5383e-12),\n",
              "  tensor(6.0024e-12)])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1.1147),\n",
              " [tensor(0.4115),\n",
              "  tensor(1.0335),\n",
              "  tensor(0.3333),\n",
              "  tensor(1.0824),\n",
              "  tensor(1.2641),\n",
              "  tensor(2.5838),\n",
              "  tensor(0.8754),\n",
              "  tensor(1.3332)])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses(net, sensory_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
