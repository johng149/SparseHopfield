{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff01c0c3d50>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = torch.randint(0,4, (3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 1, 0, 3],\n",
       "        [3, 3, 3, 1, 3],\n",
       "        [1, 2, 0, 3, 2]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.min(counts, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [0]]),\n",
       " tensor([[0],\n",
       "         [3],\n",
       "         [2]]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [3],\n",
       "         [2]],\n",
       "\n",
       "        [[0],\n",
       "         [3],\n",
       "         [2]]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.unsqueeze(0).expand(batch_size, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorts, sorti = torch.sort(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 1, 3, 3],\n",
       "         [1, 3, 3, 3, 3],\n",
       "         [0, 1, 2, 2, 3]]),\n",
       " tensor([[0, 3, 2, 1, 4],\n",
       "         [3, 0, 1, 2, 4],\n",
       "         [2, 0, 1, 4, 3]]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorts, sorti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [3],\n",
       "         [2]],\n",
       "\n",
       "        [[3],\n",
       "         [0],\n",
       "         [0]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorti[:, :batch_size].T.reshape(batch_size, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if batch_size greater than the number of memories?\n",
    "nodes, memes = sorti.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_xl = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_expands = (batch_size_xl // memes) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_expands = batch_size_xl % memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_expands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_expands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 2, 1, 4],\n",
       "        [3, 0, 1, 2, 4],\n",
       "        [2, 0, 1, 4, 3]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorti_expanded = sorti.unsqueeze(1).expand(-1, full_expands, -1).reshape(nodes, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2, 1,\n",
       "         4],\n",
       "        [3, 0, 1, 2, 4, 3, 0, 1, 2, 4, 3, 0, 1, 2, 4, 3, 0, 1, 2, 4, 3, 0, 1, 2,\n",
       "         4],\n",
       "        [2, 0, 1, 4, 3, 2, 0, 1, 4, 3, 2, 0, 1, 4, 3, 2, 0, 1, 4, 3, 2, 0, 1, 4,\n",
       "         3]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorti_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorti_selection = sorti_expanded[:, :(full_expands-1)*memes + partial_expands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2],\n",
       "         [3, 0, 1, 2, 4, 3, 0, 1, 2, 4, 3, 0, 1, 2, 4, 3, 0, 1, 2, 4, 3, 0, 1],\n",
       "         [2, 0, 1, 4, 3, 2, 0, 1, 4, 3, 2, 0, 1, 4, 3, 2, 0, 1, 4, 3, 2, 0, 1]]),\n",
       " tensor([[0],\n",
       "         [3],\n",
       "         [2]]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorti_selection, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 3, 1])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorti_selection.T.reshape(batch_size_xl, -1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_min(tensor, batch_size: int):\n",
    "    sorts, sorti = torch.sort(tensor)\n",
    "    nodes, memes = sorti.shape\n",
    "    full_expands = (batch_size // memes) + 1\n",
    "    partial_expands = batch_size % memes\n",
    "    sorti_expanded = sorti.unsqueeze(1).expand(-1, full_expands, -1).reshape(nodes, -1)\n",
    "    sorti_selection = sorti_expanded[:, :(full_expands-1)*memes + partial_expands]\n",
    "    return sorti_selection, sorti_selection.T.reshape(batch_size, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxi(x):\n",
    "  max_indices = torch.argmax(x, dim=-1, keepdim=True)\n",
    "  blank = torch.zeros_like(x)\n",
    "  return torch.scatter(blank, -1, max_indices, torch.gather(x, -1, max_indices))\n",
    "\n",
    "\n",
    "def argmaxi(x, eps=1e-8):\n",
    "  maxied = torch.abs(maxi(x))\n",
    "  factors, indices = torch.max(maxied, dim=-1)\n",
    "  factors = factors - eps\n",
    "  return maxied / factors.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def growth_argmaxi(x, counts, eps=1e-8, threshold=0.9):\n",
    "  batch_size, nodes, mems = x.shape\n",
    "  normal_path = argmaxi(x, eps)\n",
    "  indices, indices_sg = batch_min(counts, batch_size)\n",
    "  # indices_sg = indices.unsqueeze(0).expand(batch_size,-1,-1)\n",
    "  growth_path = torch.zeros_like(normal_path)\n",
    "  # values_of_interest = torch.gather(x, -1, indices_sg)\n",
    "  # taking a closer look, it doesn't seem like the exact values from\n",
    "  # the original should matter, we were just using it to divide\n",
    "  # by itself (minus an eps) in the argmaxi to turn them into 1s,\n",
    "  # to just setting it to 1 should be fine?\n",
    "  values_of_interest = 1\n",
    "  growth_path = torch.scatter(growth_path, -1, indices_sg, values_of_interest)\n",
    "  trigger_growth = torch.sum(x > threshold, dim=-1, keepdim=True) <= 0\n",
    "  grown = torch.where(trigger_growth, growth_path, normal_path)\n",
    "\n",
    "  #count_needs_update = einops.reduce(trigger_growth, 'batch nodes flag -> nodes', 'sum')\n",
    "  count_values_of_interest = torch.gather(counts, -1, indices).T.reshape(batch_size, -1, 1)\n",
    "  res = torch.where(trigger_growth, 0, count_values_of_interest)\n",
    "  batched_counts = counts.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "  updated_batch_counts = torch.scatter(batched_counts, -1, indices_sg, res)\n",
    "  updated_counts = einops.reduce(updated_batch_counts, 'batch nodes mems -> nodes mems', 'min')\n",
    "  updated_counts = updated_counts + einops.reduce(grown, 'batch nodes mems -> nodes mems', 'sum')\n",
    "\n",
    "  return grown, updated_counts.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([\n",
    "    [\n",
    "        [0.2, 0.3, 0.5],\n",
    "        [0.99, 0.01, 0.0],\n",
    "        [0.91, 0.93, 0.92],\n",
    "        [0.3, 0.3, 0.4],\n",
    "    ],\n",
    "    [\n",
    "        [0.1, 0.2, 0.7],\n",
    "        [0.1, 0.1, 0.8],\n",
    "        [0.1, 1.0, 0.8],\n",
    "        [0.1, 0.1, 0.8],\n",
    "    ],\n",
    "])\n",
    "counts = torch.tensor([\n",
    "        [12, 11, 13],\n",
    "        [10, 14, 30],\n",
    "        [15, 16, 9],\n",
    "        [3, 2, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_path\n",
      "tensor([[[0., 0., 1.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 1.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]]])\n",
      "growth_path\n",
      "tensor([[[0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.]]])\n",
      "grown\n",
      "tensor([[[0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.]]])\n",
      "tensor([[[12,  0, 13],\n",
      "         [10, 14, 30],\n",
      "         [15, 16,  9],\n",
      "         [ 3,  2,  0]],\n",
      "\n",
      "        [[ 0, 11, 13],\n",
      "         [10,  0, 30],\n",
      "         [15, 16,  9],\n",
      "         [ 3,  0,  1]]])\n"
     ]
    }
   ],
   "source": [
    "grown, updated = growth_argmaxi(test, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
